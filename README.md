# AbuseGPT

The issue of SMS phishing, commonly referred to as "smishing," poses a significant threat by deceiving individuals into revealing sensitive information or accessing malicious links via fraudulent text messages on mobile devices. Recent data indicates substantial financial losses, with the United States alone experiencing approximately $44 billion in damages due to SMS phishing in 2021. Moreover, there has been a notable surge in malicious phishing messages, skyrocketing by 1,265% since Q4 of 2022, with SMS phishing constituting 39% of all mobile-based attacks in 2023.

Furthermore, the evolution of conversational AI chatbot services, exemplified by platforms such as OpenAI's ChatGPT and Google's BARD, has been remarkable. These services, powered by large pre-trained language models (LLMs), have seen significant advancements. Our research dives into the potential repercussions of leveraging these generative AI-based chatbots by attackers to orchestrate smishing campaigns. Notably, there is a dearth of existing literature addressing the intersection of generative text-based models and the SMS phishing threat, making our study pioneering in this domain.

Our investigation yields compelling evidence indicating how attackers can exploit existing generative AI services by employing prompt injection attacks to craft smishing messages, thereby circumventing ethical standards. We underscore the necessity of proactive measures to counter the abuse of generative AI services and mitigate the risks posed by smishing attacks. Additionally, we offer insights into potential avenues for future research and guidelines aimed at safeguarding users against such malicious activities.


## Abusing BARD

![Screenshot 2024-01-19 at 11 01 34 PM](https://github.com/ashfakshibli/AbuseGPT/assets/18633979/5b21255f-23da-46fc-84b9-b0ee74a3a695)
